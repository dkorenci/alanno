{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "import torch\n",
    "from torch import nn\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSampler():\n",
    "    name = \"random\"\n",
    "\n",
    "    def select_batch(self, X_unlab, batch_size, **kwargs):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "        \n",
    "        unlab_inds = np.arange(X_unlab.shape[0])\n",
    "        return np.random.choice(unlab_inds, size=batch_size, replace=False)\n",
    "\n",
    "    def get_weights(self, X_unlab, **kwargs):\n",
    "        return np.ones(len(X_unlab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Least Confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastConfidentSampler():\n",
    "    name = \"least_confident\"\n",
    "\n",
    "    def select_batch(self, X_unlab, batch_size, model, multilabel, **kwargs):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "\n",
    "        probs = model.predict_proba(X_unlab)\n",
    "        max_probs = self.get_weights(probs, multilabel)\n",
    "\n",
    "        # Retrieve `batch_size` instances with lowest posterior probabilities.\n",
    "        top_n = np.argpartition(max_probs, batch_size)[:batch_size]\n",
    "        return top_n\n",
    "\n",
    "    def get_weights(self, probs, multilabel, **kwargs):\n",
    "        if multilabel:\n",
    "            max_binary_probs = np.where(probs > 0.5, probs, 1 - probs)\n",
    "            max_probs = np.prod(max_binary_probs, axis=1)\n",
    "        else:\n",
    "            max_probs = np.max(probs, axis=1)\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        max_probs = scaler.fit_transform(max_probs.reshape(-1, 1)).reshape(-1)\n",
    "        return max_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginSampler():\n",
    "    name = \"margin\"\n",
    "\n",
    "    def select_batch(self, X_unlab, batch_size, model, multilabel, **kwargs):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "\n",
    "        if not multilabel and hasattr(model, \"decision_function\"):\n",
    "            probs = model.decision_function(X_unlab)\n",
    "        else:\n",
    "            # the model doesn't have decision_function implemented, work with probabilities\n",
    "            probs = model.predict_proba(X_unlab)\n",
    "        min_margin = self.get_weights(probs, multilabel)\n",
    "\n",
    "        # Retrieve `batch_size` instances with smallest margins.\n",
    "        top_n = np.argpartition(min_margin, batch_size)[:batch_size]\n",
    "        return top_n\n",
    "\n",
    "    def get_weights(self, probs, multilabel, **kwargs):\n",
    "        if multilabel:\n",
    "            max_binary_probs = np.where(probs > 0.5, probs, 1 - probs)\n",
    "            second_max_binary_probs = np.copy(max_binary_probs)\n",
    "            # Take 1-p of the smallest probability in each row\n",
    "            second_max_binary_probs[\n",
    "                np.arange(second_max_binary_probs.shape[0]),\n",
    "                np.argmin(second_max_binary_probs, axis=1),\n",
    "            ] = (\n",
    "                1\n",
    "                - second_max_binary_probs[\n",
    "                    np.arange(second_max_binary_probs.shape[0]),\n",
    "                    np.argmin(second_max_binary_probs, axis=1),\n",
    "                ]\n",
    "            )\n",
    "            max_probs = np.prod(max_binary_probs, axis=1)\n",
    "            second_max_probs = np.prod(second_max_binary_probs, axis=1)\n",
    "            min_margin = max_probs - second_max_probs\n",
    "        else:\n",
    "            if len(probs.shape) == 1:\n",
    "                # If decision_function was used and task is binary\n",
    "                min_margin = abs(probs)\n",
    "            else:\n",
    "                sort_probs = np.sort(probs, 1)[:, -2:]\n",
    "                min_margin = sort_probs[:, 1] - sort_probs[:, 0]\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        min_margin = scaler.fit_transform(min_margin.reshape(-1, 1)).reshape(-1)\n",
    "        return min_margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropySampler():\n",
    "    name = \"entropy\"\n",
    "\n",
    "    def select_batch(self, X_unlab, batch_size, model, multilabel, **kwargs):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "\n",
    "        probs = model.predict_proba(X_unlab)\n",
    "\n",
    "        entropies = self.get_weights(probs, multilabel)\n",
    "\n",
    "        # Retrieve `batch_size` instances with lowest negative entropies.\n",
    "        top_n = np.argpartition(entropies, batch_size)[:batch_size]\n",
    "        return top_n\n",
    "\n",
    "    def get_weights(self, probs, multilabel, **kwargs):\n",
    "        # Clip for numerical stability.\n",
    "        probs = np.clip(probs, a_min=1e-6, a_max=1 - 1e-6)\n",
    "        if multilabel:\n",
    "            binary_entropies = -probs * np.log(probs) - (1 - probs) * np.log(1 - probs)\n",
    "            entropies = np.sum(binary_entropies, axis=1)\n",
    "        else:\n",
    "            entropies = np.sum(-probs * np.log(probs), axis=1)\n",
    "\n",
    "        # We are selecting batch with argmin\n",
    "        entropies = -entropies\n",
    "        scaler = MinMaxScaler()\n",
    "        entropies = scaler.fit_transform(entropies.reshape(-1, 1)).reshape(-1)\n",
    "        return entropies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Label Uncertainty Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelUncertaintySampler():\n",
    "    name = \"multilabel_uncertainty\"\n",
    "\n",
    "    def select_batch(self, X_unlab, batch_size, model, **kwargs):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "\n",
    "        probs = model.predict_proba(X_unlab)\n",
    "        min_margin = self.get_weights(probs)\n",
    "        top_n = np.argpartition(min_margin, batch_size)[:batch_size]\n",
    "        return top_n\n",
    "\n",
    "    def get_weights(self, probs, **kwargs):\n",
    "        min_margin = np.sum(abs(probs - 0.5), axis=1)\n",
    "        scaler = MinMaxScaler()\n",
    "        min_margin = scaler.fit_transform(min_margin.reshape(-1, 1)).reshape(-1)\n",
    "        return min_margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_types = {\"cos\": cosine_distances, \"euclid\": euclidean_distances}\n",
    "\n",
    "\n",
    "class DensitySampler():\n",
    "    name = \"density\"\n",
    "\n",
    "    def select_batch(self, X_unlab, batch_size, distance=\"cos\", **kwargs):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "\n",
    "        avg_distance = self.get_weights(X_unlab, distance)\n",
    "\n",
    "        # Retrieve `batch_size` instances with lowest average distance.\n",
    "        top_n = np.argpartition(avg_distance, batch_size)[:batch_size]\n",
    "        return top_n\n",
    "\n",
    "    def get_weights(self, X_unlab, distance=\"cos\", **kwargs):\n",
    "        if isinstance(distance, str):\n",
    "            try:\n",
    "                distance = distance_types[distance]\n",
    "            except KeyError:\n",
    "                raise ValueError(\"Distance %s not supported\" % (distance))\n",
    "\n",
    "        # Working with distance instead of similarity, because argmin is used to create batch\n",
    "        distance_matrix = distance(X_unlab)\n",
    "        avg_distance = np.sum(distance_matrix, axis=1) / (len(X_unlab) - 1)\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        avg_distance = scaler.fit_transform(avg_distance.reshape(-1, 1)).reshape(-1)\n",
    "        return avg_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Adjustable Combined Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedSampler():\n",
    "    name = \"combined\"\n",
    "\n",
    "    def select_batch(\n",
    "        self,\n",
    "        X_unlab,\n",
    "        samplers,\n",
    "        batch_size,\n",
    "        powers=None,\n",
    "        model=None,\n",
    "        multilabel=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "\n",
    "        if model:\n",
    "            probs = model.predict_proba(X_unlab)\n",
    "        else:\n",
    "            probs = None\n",
    "        final_weights = self.get_weights(\n",
    "            samplers=samplers,\n",
    "            powers=powers,\n",
    "            probs=probs,\n",
    "            X_unlab=X_unlab,\n",
    "            multilabel=multilabel,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        # Retrieve `batch_size` instances with lowest final weight.\n",
    "        top_n = np.argpartition(final_weights, batch_size)[:batch_size]\n",
    "        return top_n\n",
    "\n",
    "    def get_weights(self, samplers, powers=None, **kwargs):\n",
    "        if not powers:\n",
    "            powers = [1 for _ in range(len(samplers))]\n",
    "\n",
    "        all_weights = []\n",
    "        try:\n",
    "            for sampler, power in zip(samplers, powers):\n",
    "                sampler_weights = sampler.get_weights(**kwargs)\n",
    "                sampler_weights = np.clip(sampler_weights, a_min=1e-6, a_max=1 - 1e-6)\n",
    "                sampler_weights = np.power(sampler_weights, power)\n",
    "                all_weights.append(sampler_weights)\n",
    "        except NameError as e:\n",
    "            raise ValueError(f\"{e} for {sampler.name} sampler\")\n",
    "\n",
    "        all_weights = np.asarray(all_weights)\n",
    "        final_weights = np.prod(all_weights, axis=0)\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        final_weights = scaler.fit_transform(final_weights.reshape(-1, 1)).reshape(-1)\n",
    "        return final_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combined Entropy and Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedEntropyDensitySampler(CombinedSampler):\n",
    "    name = \"combined_entropy_density\"\n",
    "\n",
    "    def select_batch(\n",
    "        self, X_unlab, batch_size, model, multilabel, powers=None, **kwargs\n",
    "    ):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "\n",
    "        if not powers:\n",
    "            powers = [1, 1]\n",
    "        return super().select_batch(\n",
    "            X_unlab=X_unlab,\n",
    "            samplers=[EntropySampler(), DensitySampler()],\n",
    "            batch_size=batch_size,\n",
    "            powers=powers,\n",
    "            model=model,\n",
    "            multilabel=multilabel,\n",
    "        )\n",
    "\n",
    "    def get_weights(self, probs, X_unlab, multilabel, powers=None, **kwargs):\n",
    "        if not powers:\n",
    "            powers = [1, 1]\n",
    "        return super().get_weights(\n",
    "            samplers=[EntropySampler(), DensitySampler()],\n",
    "            powers=powers,\n",
    "            probs=probs,\n",
    "            X_unlab=X_unlab,\n",
    "            multilabel=multilabel,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep AL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Core-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreSet():\n",
    "    \"\"\"\n",
    "    Implementation of CoreSet :footcite:`sener2018active` Strategy. A diversity-based\n",
    "    approach using coreset selection. The embedding of each example is computed by the network’s\n",
    "    penultimate layer and the samples at each round are selected using a greedy furthest-first\n",
    "    traversal conditioned on all labeled examples.\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"core_set\"\n",
    "\n",
    "    def _furthest_first(self, unlabeled_embeddings, labeled_embeddings, n):\n",
    "        m = unlabeled_embeddings.shape[0]\n",
    "        if labeled_embeddings.shape[0] == 0:\n",
    "            min_dist = torch.tile(float(\"inf\"), m)\n",
    "        else:\n",
    "            dist_ctr = torch.cdist(unlabeled_embeddings, labeled_embeddings, p=2)\n",
    "            min_dist = torch.min(dist_ctr, dim=1)[0]\n",
    "\n",
    "        idxs = []\n",
    "\n",
    "        for i in range(n):\n",
    "            idx = torch.argmax(min_dist)\n",
    "            idxs.append(idx.item())\n",
    "            dist_new_ctr = torch.cdist(\n",
    "                unlabeled_embeddings, unlabeled_embeddings[[idx], :]\n",
    "            )\n",
    "            min_dist = torch.minimum(min_dist, dist_new_ctr[:, 0])\n",
    "\n",
    "        return idxs\n",
    "\n",
    "    def select_batch(self, X_unlab, X_lab, batch_size, model, device, **kwargs):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "\n",
    "        embedding_unlabeled = model.get_encoded(X_unlab)\n",
    "        embedding_labeled = model.get_encoded(X_lab)\n",
    "\n",
    "        top_n = self._furthest_first(embedding_unlabeled, embedding_labeled, batch_size)\n",
    "\n",
    "        return np.array(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BADGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BADGE():\n",
    "    \"\"\"\n",
    "    This method is based on the paper Deep Batch Active Learning by Diverse, Uncertain Gradient\n",
    "    Lower Bounds `DBLP-Badge`. According to the paper, this strategy, Batch Active\n",
    "    learning by Diverse Gradient Embeddings (BADGE), samples groups of points that are disparate\n",
    "    and high magnitude when represented in a hallucinated gradient space, a strategy designed to\n",
    "    incorporate both predictive uncertainty and sample diversity into every selected batch.\n",
    "    Crucially, BADGE trades off between uncertainty and diversity without requiring any hand-tuned\n",
    "    hyperparameters. Here at each round of selection, loss gradients are computed using the\n",
    "    hypothesized labels. Then to select the points to be labeled are selected by applying\n",
    "    k-means++ on these loss gradients.\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"badge\"\n",
    "\n",
    "    def _init_centers(self, X, K, device):\n",
    "        pdist = nn.PairwiseDistance(p=2)\n",
    "        ind = np.argmax([np.linalg.norm(s, 2) for s in X])\n",
    "        mu = [X[ind]]\n",
    "        inds_all = [ind]\n",
    "        cent_inds = [0.0] * len(X)\n",
    "        cent = 0\n",
    "\n",
    "        while len(mu) < K:\n",
    "            if len(mu) == 1:\n",
    "                D2 = pdist(\n",
    "                    torch.from_numpy(X).to(device), torch.from_numpy(mu[-1]).to(device)\n",
    "                )\n",
    "                D2 = torch.flatten(D2)\n",
    "                D2 = D2.cpu().numpy().astype(float)\n",
    "            else:\n",
    "                newD = pdist(\n",
    "                    torch.from_numpy(X).to(device), torch.from_numpy(mu[-1]).to(device)\n",
    "                )\n",
    "                newD = torch.flatten(newD)\n",
    "                newD = newD.cpu().numpy().astype(float)\n",
    "                for i in range(len(X)):\n",
    "                    if D2[i] > newD[i]:\n",
    "                        cent_inds[i] = cent\n",
    "                        D2[i] = newD[i]\n",
    "\n",
    "            D2 = D2.ravel().astype(float)\n",
    "            Ddist = (D2 ** 2) / sum(D2 ** 2)\n",
    "            custom_dist = stats.rv_discrete(\n",
    "                name=\"custom\", values=(np.arange(len(D2)), Ddist)\n",
    "            )\n",
    "            ind = custom_dist.rvs(size=1)[0]\n",
    "            mu.append(X[ind])\n",
    "            inds_all.append(ind)\n",
    "            cent += 1\n",
    "\n",
    "        return inds_all\n",
    "\n",
    "    def select_batch(self, X_unlab, model, batch_size, criterion, device, **kwargs):\n",
    "        if len(X_unlab) <= batch_size:\n",
    "            return np.arange(len(X_unlab))\n",
    "\n",
    "        grad_embedding = model.get_grad_embedding(X_unlab, criterion, grad_embedding_type=\"linear\")\n",
    "        grad_embedding = grad_embedding.cpu().detach().numpy()\n",
    "        top_n = self._init_centers(grad_embedding, batch_size, device)\n",
    "        return np.array(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_MAPPING = {}\n",
    "AL_MAPPING[\"uniform\"] = RandomSampler\n",
    "AL_MAPPING[\"least_conf\"] = LeastConfidentSampler\n",
    "AL_MAPPING[\"margin\"] = MarginSampler\n",
    "AL_MAPPING[\"entropy\"] = EntropySampler\n",
    "AL_MAPPING[\"multilab_uncert\"] = MultilabelUncertaintySampler\n",
    "AL_MAPPING[\"entropy_density\"] = CombinedEntropyDensitySampler\n",
    "AL_MAPPING[\"core_set\"] = CoreSet\n",
    "AL_MAPPING[\"badge\"] = BADGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Choose AL methods for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_methods = [AL_MAPPING[\"uniform\"](), AL_MAPPING[\"least_conf\"](), AL_MAPPING[\"margin\"](), AL_MAPPING[\"entropy\"]()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose model\n",
    "\n",
    "- Model has to implement function `predict_proba` which returns probabilities of all classes (if using `Margin` AL method `decision_function` function can be implemented insted).\n",
    "- If using `Core-set` AL method, model has to implement function `get_encoded` which returns embeddings of model's penultimate layer for each example.\n",
    "- If using `BADGE` AL method, model has to implement function `get_grad_embedding` which returns gradient embeddings of models' last layer for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from podium import Vocab, Field, LabelField\n",
    "from podium.datasets import SST\n",
    "\n",
    "vocab = Vocab(max_size=5000, specials=())\n",
    "text = Field(name='text', numericalizer=vocab, tokenizer=None, disable_batch_matrix=True)\n",
    "label = LabelField(name='label')\n",
    "fields = {'text': text, 'label': label}\n",
    "train, dev, test = SST.get_dataset_splits(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pool = [x[1] for x in train.text] + [x[1] for x in dev.text]\n",
    "y_pool = [1 if y[1] == \"positive\" else 0 for y in train.label] + [1 if y[1] == \"positive\" else 0 for y in dev.label]\n",
    "X_labeled = []\n",
    "y_labeled = []\n",
    "X_test = [x[1] for x in test.text]\n",
    "y_test = [1 if y[1] == \"positive\" else 0 for y in test.label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Choose Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_vectorizer():\n",
    "    return TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AL LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "warm_start_size = 100\n",
    "vectorizer = get_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create warm start set\n",
    "random_sampler = RandomSampler()\n",
    "warm_start_inds = random_sampler.select_batch(np.array(X_pool), warm_start_size).tolist()\n",
    "warm_start_inds.sort(reverse=True)\n",
    "X_labeled = [X_pool.pop(i) for i in warm_start_inds]\n",
    "y_labeled = [y_pool.pop(i) for i in warm_start_inds]\n",
    "X_labeled_vec = vectorizer.fit_transform(X_labeled)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "X_pool_vec = vectorizer.transform(X_pool)\n",
    "model.fit(X_labeled_vec, y_labeled)\n",
    "res_init = f1_score(y_test, model.predict(X_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method #1. random -> Batch #1, Pool size=7592\n",
      "Method #1. random -> Batch #2, Pool size=7492\n",
      "Method #1. random -> Batch #3, Pool size=7392\n",
      "Method #1. random -> Batch #4, Pool size=7292\n",
      "Method #1. random -> Batch #5, Pool size=7192\n",
      "Method #1. random -> Batch #6, Pool size=7092\n",
      "Method #1. random -> Batch #7, Pool size=6992\n",
      "Method #1. random -> Batch #8, Pool size=6892\n",
      "Method #1. random -> Batch #9, Pool size=6792\n",
      "Method #1. random -> Batch #10, Pool size=6692\n",
      "Method #1. random -> Batch #11, Pool size=6592\n",
      "Method #1. random -> Batch #12, Pool size=6492\n",
      "Method #1. random -> Batch #13, Pool size=6392\n",
      "Method #1. random -> Batch #14, Pool size=6292\n",
      "Method #1. random -> Batch #15, Pool size=6192\n",
      "Method #1. random -> Batch #16, Pool size=6092\n",
      "Method #1. random -> Batch #17, Pool size=5992\n",
      "Method #1. random -> Batch #18, Pool size=5892\n",
      "Method #1. random -> Batch #19, Pool size=5792\n",
      "Method #1. random -> Batch #20, Pool size=5692\n",
      "Method #1. random -> Batch #21, Pool size=5592\n",
      "Method #1. random -> Batch #22, Pool size=5492\n",
      "Method #1. random -> Batch #23, Pool size=5392\n",
      "Method #1. random -> Batch #24, Pool size=5292\n",
      "Method #1. random -> Batch #25, Pool size=5192\n",
      "Method #1. random -> Batch #26, Pool size=5092\n",
      "Method #1. random -> Batch #27, Pool size=4992\n",
      "Method #1. random -> Batch #28, Pool size=4892\n",
      "Method #1. random -> Batch #29, Pool size=4792\n",
      "Method #1. random -> Batch #30, Pool size=4692\n",
      "Method #1. random -> Batch #31, Pool size=4592\n",
      "Method #1. random -> Batch #32, Pool size=4492\n",
      "Method #1. random -> Batch #33, Pool size=4392\n",
      "Method #1. random -> Batch #34, Pool size=4292\n",
      "Method #1. random -> Batch #35, Pool size=4192\n",
      "Method #1. random -> Batch #36, Pool size=4092\n",
      "Method #1. random -> Batch #37, Pool size=3992\n",
      "Method #1. random -> Batch #38, Pool size=3892\n",
      "Method #1. random -> Batch #39, Pool size=3792\n",
      "Method #1. random -> Batch #40, Pool size=3692\n",
      "Method #1. random -> Batch #41, Pool size=3592\n",
      "Method #1. random -> Batch #42, Pool size=3492\n",
      "Method #1. random -> Batch #43, Pool size=3392\n",
      "Method #1. random -> Batch #44, Pool size=3292\n",
      "Method #1. random -> Batch #45, Pool size=3192\n",
      "Method #1. random -> Batch #46, Pool size=3092\n",
      "Method #1. random -> Batch #47, Pool size=2992\n",
      "Method #1. random -> Batch #48, Pool size=2892\n",
      "Method #1. random -> Batch #49, Pool size=2792\n",
      "Method #1. random -> Batch #50, Pool size=2692\n",
      "Method #1. random -> Batch #51, Pool size=2592\n",
      "Method #1. random -> Batch #52, Pool size=2492\n",
      "Method #1. random -> Batch #53, Pool size=2392\n",
      "Method #1. random -> Batch #54, Pool size=2292\n",
      "Method #1. random -> Batch #55, Pool size=2192\n",
      "Method #1. random -> Batch #56, Pool size=2092\n",
      "Method #1. random -> Batch #57, Pool size=1992\n",
      "Method #1. random -> Batch #58, Pool size=1892\n",
      "Method #1. random -> Batch #59, Pool size=1792\n",
      "Method #1. random -> Batch #60, Pool size=1692\n",
      "Method #1. random -> Batch #61, Pool size=1592\n",
      "Method #1. random -> Batch #62, Pool size=1492\n",
      "Method #1. random -> Batch #63, Pool size=1392\n",
      "Method #1. random -> Batch #64, Pool size=1292\n",
      "Method #1. random -> Batch #65, Pool size=1192\n",
      "Method #1. random -> Batch #66, Pool size=1092\n",
      "Method #1. random -> Batch #67, Pool size=992\n",
      "Method #1. random -> Batch #68, Pool size=892\n",
      "Method #1. random -> Batch #69, Pool size=792\n",
      "Method #1. random -> Batch #70, Pool size=692\n",
      "Method #1. random -> Batch #71, Pool size=592\n",
      "Method #1. random -> Batch #72, Pool size=492\n",
      "Method #1. random -> Batch #73, Pool size=392\n",
      "Method #1. random -> Batch #74, Pool size=292\n",
      "Method #1. random -> Batch #75, Pool size=192\n",
      "Method #1. random -> Batch #76, Pool size=92\n",
      "Method #2. least_confident -> Batch #1, Pool size=7592\n",
      "Method #2. least_confident -> Batch #2, Pool size=7492\n",
      "Method #2. least_confident -> Batch #3, Pool size=7392\n",
      "Method #2. least_confident -> Batch #4, Pool size=7292\n",
      "Method #2. least_confident -> Batch #5, Pool size=7192\n",
      "Method #2. least_confident -> Batch #6, Pool size=7092\n",
      "Method #2. least_confident -> Batch #7, Pool size=6992\n",
      "Method #2. least_confident -> Batch #8, Pool size=6892\n",
      "Method #2. least_confident -> Batch #9, Pool size=6792\n",
      "Method #2. least_confident -> Batch #10, Pool size=6692\n",
      "Method #2. least_confident -> Batch #11, Pool size=6592\n",
      "Method #2. least_confident -> Batch #12, Pool size=6492\n",
      "Method #2. least_confident -> Batch #13, Pool size=6392\n",
      "Method #2. least_confident -> Batch #14, Pool size=6292\n",
      "Method #2. least_confident -> Batch #15, Pool size=6192\n",
      "Method #2. least_confident -> Batch #16, Pool size=6092\n",
      "Method #2. least_confident -> Batch #17, Pool size=5992\n",
      "Method #2. least_confident -> Batch #18, Pool size=5892\n",
      "Method #2. least_confident -> Batch #19, Pool size=5792\n",
      "Method #2. least_confident -> Batch #20, Pool size=5692\n",
      "Method #2. least_confident -> Batch #21, Pool size=5592\n",
      "Method #2. least_confident -> Batch #22, Pool size=5492\n",
      "Method #2. least_confident -> Batch #23, Pool size=5392\n",
      "Method #2. least_confident -> Batch #24, Pool size=5292\n",
      "Method #2. least_confident -> Batch #25, Pool size=5192\n",
      "Method #2. least_confident -> Batch #26, Pool size=5092\n",
      "Method #2. least_confident -> Batch #27, Pool size=4992\n",
      "Method #2. least_confident -> Batch #28, Pool size=4892\n",
      "Method #2. least_confident -> Batch #29, Pool size=4792\n",
      "Method #2. least_confident -> Batch #30, Pool size=4692\n",
      "Method #2. least_confident -> Batch #31, Pool size=4592\n",
      "Method #2. least_confident -> Batch #32, Pool size=4492\n",
      "Method #2. least_confident -> Batch #33, Pool size=4392\n",
      "Method #2. least_confident -> Batch #34, Pool size=4292\n",
      "Method #2. least_confident -> Batch #35, Pool size=4192\n",
      "Method #2. least_confident -> Batch #36, Pool size=4092\n",
      "Method #2. least_confident -> Batch #37, Pool size=3992\n",
      "Method #2. least_confident -> Batch #38, Pool size=3892\n",
      "Method #2. least_confident -> Batch #39, Pool size=3792\n",
      "Method #2. least_confident -> Batch #40, Pool size=3692\n",
      "Method #2. least_confident -> Batch #41, Pool size=3592\n",
      "Method #2. least_confident -> Batch #42, Pool size=3492\n",
      "Method #2. least_confident -> Batch #43, Pool size=3392\n",
      "Method #2. least_confident -> Batch #44, Pool size=3292\n",
      "Method #2. least_confident -> Batch #45, Pool size=3192\n",
      "Method #2. least_confident -> Batch #46, Pool size=3092\n",
      "Method #2. least_confident -> Batch #47, Pool size=2992\n",
      "Method #2. least_confident -> Batch #48, Pool size=2892\n",
      "Method #2. least_confident -> Batch #49, Pool size=2792\n",
      "Method #2. least_confident -> Batch #50, Pool size=2692\n",
      "Method #2. least_confident -> Batch #51, Pool size=2592\n",
      "Method #2. least_confident -> Batch #52, Pool size=2492\n",
      "Method #2. least_confident -> Batch #53, Pool size=2392\n",
      "Method #2. least_confident -> Batch #54, Pool size=2292\n",
      "Method #2. least_confident -> Batch #55, Pool size=2192\n",
      "Method #2. least_confident -> Batch #56, Pool size=2092\n",
      "Method #2. least_confident -> Batch #57, Pool size=1992\n",
      "Method #2. least_confident -> Batch #58, Pool size=1892\n",
      "Method #2. least_confident -> Batch #59, Pool size=1792\n",
      "Method #2. least_confident -> Batch #60, Pool size=1692\n",
      "Method #2. least_confident -> Batch #61, Pool size=1592\n",
      "Method #2. least_confident -> Batch #62, Pool size=1492\n",
      "Method #2. least_confident -> Batch #63, Pool size=1392\n",
      "Method #2. least_confident -> Batch #64, Pool size=1292\n",
      "Method #2. least_confident -> Batch #65, Pool size=1192\n",
      "Method #2. least_confident -> Batch #66, Pool size=1092\n",
      "Method #2. least_confident -> Batch #67, Pool size=992\n",
      "Method #2. least_confident -> Batch #68, Pool size=892\n",
      "Method #2. least_confident -> Batch #69, Pool size=792\n",
      "Method #2. least_confident -> Batch #70, Pool size=692\n",
      "Method #2. least_confident -> Batch #71, Pool size=592\n",
      "Method #2. least_confident -> Batch #72, Pool size=492\n",
      "Method #2. least_confident -> Batch #73, Pool size=392\n",
      "Method #2. least_confident -> Batch #74, Pool size=292\n",
      "Method #2. least_confident -> Batch #75, Pool size=192\n",
      "Method #2. least_confident -> Batch #76, Pool size=92\n",
      "Method #3. margin -> Batch #1, Pool size=7592\n",
      "Method #3. margin -> Batch #2, Pool size=7492\n",
      "Method #3. margin -> Batch #3, Pool size=7392\n",
      "Method #3. margin -> Batch #4, Pool size=7292\n",
      "Method #3. margin -> Batch #5, Pool size=7192\n",
      "Method #3. margin -> Batch #6, Pool size=7092\n",
      "Method #3. margin -> Batch #7, Pool size=6992\n",
      "Method #3. margin -> Batch #8, Pool size=6892\n",
      "Method #3. margin -> Batch #9, Pool size=6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method #3. margin -> Batch #10, Pool size=6692\n",
      "Method #3. margin -> Batch #11, Pool size=6592\n",
      "Method #3. margin -> Batch #12, Pool size=6492\n",
      "Method #3. margin -> Batch #13, Pool size=6392\n",
      "Method #3. margin -> Batch #14, Pool size=6292\n",
      "Method #3. margin -> Batch #15, Pool size=6192\n",
      "Method #3. margin -> Batch #16, Pool size=6092\n",
      "Method #3. margin -> Batch #17, Pool size=5992\n",
      "Method #3. margin -> Batch #18, Pool size=5892\n",
      "Method #3. margin -> Batch #19, Pool size=5792\n",
      "Method #3. margin -> Batch #20, Pool size=5692\n",
      "Method #3. margin -> Batch #21, Pool size=5592\n",
      "Method #3. margin -> Batch #22, Pool size=5492\n",
      "Method #3. margin -> Batch #23, Pool size=5392\n",
      "Method #3. margin -> Batch #24, Pool size=5292\n",
      "Method #3. margin -> Batch #25, Pool size=5192\n",
      "Method #3. margin -> Batch #26, Pool size=5092\n",
      "Method #3. margin -> Batch #27, Pool size=4992\n",
      "Method #3. margin -> Batch #28, Pool size=4892\n",
      "Method #3. margin -> Batch #29, Pool size=4792\n",
      "Method #3. margin -> Batch #30, Pool size=4692\n",
      "Method #3. margin -> Batch #31, Pool size=4592\n",
      "Method #3. margin -> Batch #32, Pool size=4492\n",
      "Method #3. margin -> Batch #33, Pool size=4392\n",
      "Method #3. margin -> Batch #34, Pool size=4292\n",
      "Method #3. margin -> Batch #35, Pool size=4192\n",
      "Method #3. margin -> Batch #36, Pool size=4092\n",
      "Method #3. margin -> Batch #37, Pool size=3992\n",
      "Method #3. margin -> Batch #38, Pool size=3892\n",
      "Method #3. margin -> Batch #39, Pool size=3792\n",
      "Method #3. margin -> Batch #40, Pool size=3692\n",
      "Method #3. margin -> Batch #41, Pool size=3592\n",
      "Method #3. margin -> Batch #42, Pool size=3492\n",
      "Method #3. margin -> Batch #43, Pool size=3392\n",
      "Method #3. margin -> Batch #44, Pool size=3292\n",
      "Method #3. margin -> Batch #45, Pool size=3192\n",
      "Method #3. margin -> Batch #46, Pool size=3092\n",
      "Method #3. margin -> Batch #47, Pool size=2992\n",
      "Method #3. margin -> Batch #48, Pool size=2892\n",
      "Method #3. margin -> Batch #49, Pool size=2792\n",
      "Method #3. margin -> Batch #50, Pool size=2692\n",
      "Method #3. margin -> Batch #51, Pool size=2592\n",
      "Method #3. margin -> Batch #52, Pool size=2492\n",
      "Method #3. margin -> Batch #53, Pool size=2392\n",
      "Method #3. margin -> Batch #54, Pool size=2292\n",
      "Method #3. margin -> Batch #55, Pool size=2192\n",
      "Method #3. margin -> Batch #56, Pool size=2092\n",
      "Method #3. margin -> Batch #57, Pool size=1992\n",
      "Method #3. margin -> Batch #58, Pool size=1892\n",
      "Method #3. margin -> Batch #59, Pool size=1792\n",
      "Method #3. margin -> Batch #60, Pool size=1692\n",
      "Method #3. margin -> Batch #61, Pool size=1592\n",
      "Method #3. margin -> Batch #62, Pool size=1492\n",
      "Method #3. margin -> Batch #63, Pool size=1392\n",
      "Method #3. margin -> Batch #64, Pool size=1292\n",
      "Method #3. margin -> Batch #65, Pool size=1192\n",
      "Method #3. margin -> Batch #66, Pool size=1092\n",
      "Method #3. margin -> Batch #67, Pool size=992\n",
      "Method #3. margin -> Batch #68, Pool size=892\n",
      "Method #3. margin -> Batch #69, Pool size=792\n",
      "Method #3. margin -> Batch #70, Pool size=692\n",
      "Method #3. margin -> Batch #71, Pool size=592\n",
      "Method #3. margin -> Batch #72, Pool size=492\n",
      "Method #3. margin -> Batch #73, Pool size=392\n",
      "Method #3. margin -> Batch #74, Pool size=292\n",
      "Method #3. margin -> Batch #75, Pool size=192\n",
      "Method #3. margin -> Batch #76, Pool size=92\n",
      "Method #4. entropy -> Batch #1, Pool size=7592\n",
      "Method #4. entropy -> Batch #2, Pool size=7492\n",
      "Method #4. entropy -> Batch #3, Pool size=7392\n",
      "Method #4. entropy -> Batch #4, Pool size=7292\n",
      "Method #4. entropy -> Batch #5, Pool size=7192\n",
      "Method #4. entropy -> Batch #6, Pool size=7092\n",
      "Method #4. entropy -> Batch #7, Pool size=6992\n",
      "Method #4. entropy -> Batch #8, Pool size=6892\n",
      "Method #4. entropy -> Batch #9, Pool size=6792\n",
      "Method #4. entropy -> Batch #10, Pool size=6692\n",
      "Method #4. entropy -> Batch #11, Pool size=6592\n",
      "Method #4. entropy -> Batch #12, Pool size=6492\n",
      "Method #4. entropy -> Batch #13, Pool size=6392\n",
      "Method #4. entropy -> Batch #14, Pool size=6292\n",
      "Method #4. entropy -> Batch #15, Pool size=6192\n",
      "Method #4. entropy -> Batch #16, Pool size=6092\n",
      "Method #4. entropy -> Batch #17, Pool size=5992\n",
      "Method #4. entropy -> Batch #18, Pool size=5892\n",
      "Method #4. entropy -> Batch #19, Pool size=5792\n",
      "Method #4. entropy -> Batch #20, Pool size=5692\n",
      "Method #4. entropy -> Batch #21, Pool size=5592\n",
      "Method #4. entropy -> Batch #22, Pool size=5492\n",
      "Method #4. entropy -> Batch #23, Pool size=5392\n",
      "Method #4. entropy -> Batch #24, Pool size=5292\n",
      "Method #4. entropy -> Batch #25, Pool size=5192\n",
      "Method #4. entropy -> Batch #26, Pool size=5092\n",
      "Method #4. entropy -> Batch #27, Pool size=4992\n",
      "Method #4. entropy -> Batch #28, Pool size=4892\n",
      "Method #4. entropy -> Batch #29, Pool size=4792\n",
      "Method #4. entropy -> Batch #30, Pool size=4692\n",
      "Method #4. entropy -> Batch #31, Pool size=4592\n",
      "Method #4. entropy -> Batch #32, Pool size=4492\n",
      "Method #4. entropy -> Batch #33, Pool size=4392\n",
      "Method #4. entropy -> Batch #34, Pool size=4292\n",
      "Method #4. entropy -> Batch #35, Pool size=4192\n",
      "Method #4. entropy -> Batch #36, Pool size=4092\n",
      "Method #4. entropy -> Batch #37, Pool size=3992\n",
      "Method #4. entropy -> Batch #38, Pool size=3892\n",
      "Method #4. entropy -> Batch #39, Pool size=3792\n",
      "Method #4. entropy -> Batch #40, Pool size=3692\n",
      "Method #4. entropy -> Batch #41, Pool size=3592\n",
      "Method #4. entropy -> Batch #42, Pool size=3492\n",
      "Method #4. entropy -> Batch #43, Pool size=3392\n",
      "Method #4. entropy -> Batch #44, Pool size=3292\n",
      "Method #4. entropy -> Batch #45, Pool size=3192\n",
      "Method #4. entropy -> Batch #46, Pool size=3092\n",
      "Method #4. entropy -> Batch #47, Pool size=2992\n",
      "Method #4. entropy -> Batch #48, Pool size=2892\n",
      "Method #4. entropy -> Batch #49, Pool size=2792\n",
      "Method #4. entropy -> Batch #50, Pool size=2692\n",
      "Method #4. entropy -> Batch #51, Pool size=2592\n",
      "Method #4. entropy -> Batch #52, Pool size=2492\n",
      "Method #4. entropy -> Batch #53, Pool size=2392\n",
      "Method #4. entropy -> Batch #54, Pool size=2292\n",
      "Method #4. entropy -> Batch #55, Pool size=2192\n",
      "Method #4. entropy -> Batch #56, Pool size=2092\n",
      "Method #4. entropy -> Batch #57, Pool size=1992\n",
      "Method #4. entropy -> Batch #58, Pool size=1892\n",
      "Method #4. entropy -> Batch #59, Pool size=1792\n",
      "Method #4. entropy -> Batch #60, Pool size=1692\n",
      "Method #4. entropy -> Batch #61, Pool size=1592\n",
      "Method #4. entropy -> Batch #62, Pool size=1492\n",
      "Method #4. entropy -> Batch #63, Pool size=1392\n",
      "Method #4. entropy -> Batch #64, Pool size=1292\n",
      "Method #4. entropy -> Batch #65, Pool size=1192\n",
      "Method #4. entropy -> Batch #66, Pool size=1092\n",
      "Method #4. entropy -> Batch #67, Pool size=992\n",
      "Method #4. entropy -> Batch #68, Pool size=892\n",
      "Method #4. entropy -> Batch #69, Pool size=792\n",
      "Method #4. entropy -> Batch #70, Pool size=692\n",
      "Method #4. entropy -> Batch #71, Pool size=592\n",
      "Method #4. entropy -> Batch #72, Pool size=492\n",
      "Method #4. entropy -> Batch #73, Pool size=392\n",
      "Method #4. entropy -> Batch #74, Pool size=292\n",
      "Method #4. entropy -> Batch #75, Pool size=192\n",
      "Method #4. entropy -> Batch #76, Pool size=92\n"
     ]
    }
   ],
   "source": [
    "# AL LOOP\n",
    "results = []\n",
    "for i, method in enumerate(al_methods):\n",
    "    scores = [res_init]\n",
    "    j=0\n",
    "    while True:\n",
    "        al_kwargs = dict(\n",
    "            X_unlab=X_pool_vec.toarray(),\n",
    "            X_lab=X_labeled_vec,\n",
    "            model=model,\n",
    "            batch_size=batch_size,\n",
    "            multilabel=False,\n",
    "            criterion=None,\n",
    "            device=None\n",
    "        )\n",
    "        al_inds = method.select_batch(**al_kwargs).tolist()\n",
    "        al_inds.sort(reverse=True)\n",
    "        \n",
    "        X_labeled.extend([X_pool.pop(i) for i in al_inds])\n",
    "        y_labeled.extend([y_pool.pop(i) for i in al_inds])\n",
    "        \n",
    "        if not len(X_pool):\n",
    "            break\n",
    "        \n",
    "        X_labeled_vec = vectorizer.fit_transform(X_labeled)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "        X_pool_vec = vectorizer.transform(X_pool)\n",
    "        model.fit(X_labeled_vec, y_labeled)\n",
    "        \n",
    "        scores.append(f1_score(y_test, model.predict(X_test_vec)))\n",
    "        j+=1\n",
    "        print(f\"Method #{i+1}. {method.name} -> Batch #{j}, Pool size={len(X_pool)}\")   \n",
    "        \n",
    "    X_pool = X_labeled\n",
    "    y_pool = y_labeled\n",
    "    X_labeled = [X_pool.pop(i) for i in warm_start_inds]\n",
    "    y_labeled = [y_pool.pop(i) for i in warm_start_inds]\n",
    "    X_labeled_vec = vectorizer.fit_transform(X_labeled)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    X_pool_vec = vectorizer.transform(X_pool)\n",
    "    model.fit(X_labeled_vec, y_labeled)\n",
    "    results.append((method.name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, scores in results:\n",
    "    plt.plot(range(len(scores)), scores, label=(name))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
